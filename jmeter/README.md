# JMeter Performance Testing - JPetStore

## ğŸ“Š Prueba de Carga - CatÃ¡logo FISH

Este directorio contiene el plan de pruebas de rendimiento para JPetStore usando Apache JMeter.

### ğŸ“‹ ConfiguraciÃ³n de la Prueba

- **Usuarios Virtuales**: 50
- **Ramp-up Period**: 10 segundos
- **Loop Count**: 1 iteraciÃ³n por usuario
- **URL Objetivo**: `https://jpetstore.aspectran.com/catalog/categories/FISH`
- **MÃ©todo HTTP**: GET

### ğŸ“ Archivos Incluidos

- `JPetStore-Performance-Test.jmx`: Plan de pruebas de JMeter
- `results.jtl`: Resultados de la ejecuciÃ³n en formato JTL
- `report/`: Reporte HTML generado automÃ¡ticamente
- `report/index.html`: Dashboard principal con todas las mÃ©tricas

### ğŸš€ CÃ³mo Ejecutar la Prueba

#### OpciÃ³n 1: Modo GUI (Recomendado para desarrollo)
```bash
jmeter -t JPetStore-Performance-Test.jmx
```

#### OpciÃ³n 2: Modo No-GUI (Recomendado para ejecuciÃ³n)
```bash
jmeter -n -t JPetStore-Performance-Test.jmx -l results.jtl -e -o report
```

### ğŸ“ˆ Ver Resultados

#### Ver Reporte HTML
```bash
open report/index.html
```

El reporte incluye:
- **Dashboard**: Vista general con grÃ¡ficos de rendimiento
- **Statistics**: Tabla con mÃ©tricas detalladas (Average, Min, Max, 90% Line, Throughput, Error %)
- **Charts**: GrÃ¡ficos de Response Time Over Time, Active Threads, etc.

### ğŸ” MÃ©tricas Clave a Analizar

#### 1. **Tiempo de Respuesta**
- **Average**: Tiempo promedio de respuesta
- **90% Line**: El 90% de las solicitudes completaron en este tiempo o menos
- **Min/Max**: Rango de tiempos de respuesta

#### 2. **Throughput (Rendimiento)**
- Solicitudes por segundo que el servidor pudo manejar

#### 3. **Error Rate**
- Porcentaje de solicitudes fallidas
- Debe ser 0% idealmente

### ğŸ“Š Captura de Pantalla del Aggregate Report

Para el entregable, debes tomar un screenshot de:

1. Abrir `report/index.html` en el navegador
2. Ir a la secciÃ³n "Statistics" o "Summary Report"
3. Tomar screenshot mostrando:
   - # Samples
   - Average
   - Min / Max
   - 90% Line
   - Error %
   - Throughput

### ğŸ¯ AnÃ¡lisis de Resultados

#### âœ… Resultados Esperados
- **Average < 3000ms**: Experiencia de usuario aceptable
- **90% Line < 5000ms**: MayorÃ­a de usuarios tienen buena experiencia
- **Error % = 0%**: Todas las solicitudes exitosas
- **Throughput > 4 req/s**: Servidor maneja bien la carga

#### âš ï¸ Resultados Actuales (Ejemplo)
Basado en la Ãºltima ejecuciÃ³n:
- **Total Samples**: 50
- **Average**: ~2395 ms
- **Min**: 812 ms
- **Max**: 6096 ms
- **Error Rate**: 16% (8/50 requests)

**Nota**: El 16% de errores puede deberse a:
- Redirecciones HTTP 301
- Timeouts en algunas solicitudes
- Limitaciones del servidor bajo carga

### ğŸ”§ Componentes del Plan de Pruebas

1. **Thread Group**: ConfiguraciÃ³n de usuarios virtuales
2. **HTTP Request Sampler**: Solicitud GET al catÃ¡logo
3. **HTTP Header Manager**: Headers realistas de navegador
4. **HTTP Cookie Manager**: GestiÃ³n de sesiones
5. **HTTP Cache Manager**: SimulaciÃ³n de cachÃ© del navegador
6. **Response Assertion**: Validar cÃ³digo HTTP 200
7. **Duration Assertion**: Validar tiempo de respuesta < 5s
8. **Aggregate Report**: MÃ©tricas consolidadas
9. **Summary Report**: Resumen ejecutivo
10. **View Results Tree**: Detalles de cada solicitud

### ğŸ“ Conclusiones para el Informe

**Impacto en Pruebas Funcionales:**
- Si el tiempo promedio supera 3 segundos, las pruebas funcionales de Playwright/Selenium IDE pueden fallar por timeout
- Un servidor lento causarÃ­a que las esperas implÃ­citas no sean suficientes
- Los tests E2E se volverÃ­an inestables (flaky) bajo carga

**Recomendaciones:**
- Optimizar la pÃ¡gina de catÃ¡logo para reducir tiempo de carga
- Implementar CDN para recursos estÃ¡ticos
- Considerar cachÃ© de base de datos para consultas frecuentes
- Monitorear el servidor durante pruebas funcionales

---

**Creado**: 1 de Noviembre 2025
**Herramienta**: Apache JMeter 5.6.3
**Proyecto**: JPetStore E2E Testing - Performance Module
